#+TITLE: Machine Learning User Domain Discovery
#+AUTHOR: Olgierd Grodzki, Mateusz Rzeszutek
#+OPTIONS: toc:t todo:nil ^:{}
#+STARTUP: beamer
#+STARTUP: hidestars

#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [presentation, 10pt]
#+BEAMER_FRAME_LEVEL: 2

#+LATEX_HEADER: \usepackage{amsfonts}
#+LATEX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usetheme{Madrid}
#+LaTeX_HEADER: \usefonttheme{structurebold}
#+LaTeX_HEADER: \usecolortheme{default}
#+LaTeX_HEADER: \beamertemplateballitem
#+LaTeX_HEADER: \setbeamersize{text margin left=5mm}
#+LaTeX_HEADER: \setbeamercovered{transparent}
#+LaTeX_HEADER: \setbeamertemplate{navigation symbols}{}

#+LaTeX_HEADER: \AtBeginSection[]{\frame<handout:0>{\frametitle[allowframebreaks]{Presentation Outline}\tableofcontents[current,currentsubsection,hideothersubsections]}}

#+LaTeX_HEADER: \institute[AGH-UST]{Institute of Applied Computer science\\ AGH University of Science and Technology}

#+LaTeX_HEADER: \usepackage[english]{babel}

#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}

* Introduction
** Problem description
The goal of this project is to create an Android application which changes
its user interface depending on the user's location - the collected GPS data 
has to be clustered into 'domains' using a clustering algotrithm and possibly 
some other data.

** Problem description, continued
For algorithm prototyping we used the Python Programming Language with
NumPy, SciPy, pandas and matplotlib libraries.

* Theory and implementation
** K-means
*** Input:                                               :B_normal:
    :PROPERTIES:
    :BEAMER_env: normal
    :END:
+ $K$ -- number of clusters
+ $\{x^{(1)}, ..., x^{(m)}\}$ -- training set

*** Algorithm:                                                     :B_normal:
    :PROPERTIES:
    :BEAMER_env: normal
    :END:
1. Randomly initialize /K/ cluster centroids $\mu_1$, $\mu_2$, ..., $\mu_K \in \mathbb{R}^n$
2. Repeat until convergence:
   1. *Cluster assignment step* -- for $i \in \{1, ..., m\}$: \\
      $c^{(i)}$ := index (from 1 to /K/) of cluster centroid closest to $x^{(i)}$ ($\argmin\limits_k \|x^{(i)} - \mu_k\|^2$)
   2. *Update step* -- for $k \in \{1, ..., K\}$: \\
      $\mu_K$ := average (mean) of points assigned to cluster /k/

** Distortion
The distortion is defined as follows:
#+BEGIN_LaTeX
  \[
  \frac{1}{p}
  \min\limits_{
    \mathbf{c}_1, ..., \mathbf{c}_K
  }
  E\big[
  (\mathbf{X} - \mathbf{c}_{\mathbf{X}})
  \Gamma^{-1}
  (\mathbf{X} - \mathbf{c}_{\mathbf{X}})^T
  \big]
  \]
#+END_LaTeX
where
+ $\mathbf{X}$ -- a /p/-dimensional random variable; a mixture of $G$ components
+ $\Gamma$ -- covariance matrix
+ $\mathbf{c}_1, ..., \mathbf{c}_K$ -- a set of all $K$ cluster centers
+ $\mathbf{c}_{\mathbf{X}}$ -- the closest cluster center to a given sample of $X$
+ $E$ -- expected value

** Calculating distortion
It is impossible to calculate a minimum for *all* possible sets of clusters.
Distortion calculation is usually implemented in one of those two ways:
+ calculate the distortion for some chosen set of clusters, or
+ calculate distortions for a few sets of clusters, and choose the smallest value

** Distortion function implementation
Our implementation:

#+BEGIN_SRC python
  import numpy as np
  import scipy.linalg as la
  
  def distortion(data, idx, centroids, gamma = None):
      # data dimensions
      M, N = data.shape
      K = len(centroids)
  
      # if no covariance matrix is passed, use an identity matrix
      # in this case the distortion is simply mean squared error
      if gamma is None:
          gamma = np.eye(N)
      cov = np.matrix(la.inv(gamma))
  
      # calculate distortion
      distortion = 0
      for i in range(M):
          temp = np.matrix(data[i] - centroids[idx[i]])
          distortion += temp * cov * temp.T
      distortion = distortion / (M * N)
  
      return distortion
  
#+END_SRC

** Finding the number of clusters in a data set
An information theoretic approach algorithm \cite{information-theoretic-approach}:
1. compute distortion $d(k)$ for all $1 < K < n$, using a standard clustering algorithm (K-means)
2. choose a transformation power, $Y > 0$; a typical value is $\frac{p}{2}$
3. transform the distortion curve by a negative power: $D(K) = d(K)^{-Y}$
4. calculate jumps: $J(K) = D(K) - D(K -1)$
5. the largest jump ($K^* = \argmax\limits_K J(K)$) represents the best choice for the number of clusters

** An information theoretic approach -- implementation
Our implementation:
#+BEGIN_SRC python
  import numpy as np
  import scipy.cluster.vq as cluster
  
  def jump_method(data, n = None, max_iterations = 10):
      M, N = data.shape
      if n is None:
          n = int(np.sqrt(M))
      Y = 0.5 * N
      tf_dist = np.zeros(n + 1)
      jump = np.zeros(n)
  
      # for all k = 1..n
      for k in range(1, n + 1):
          centroids, idx = cluster.kmeans2(data, k, minit = 'points', 
                                           iter = max_iterations)
          # calculate distortion
          dist = distortion(data, idx, centroids)
          # calculate transformed distortion
          tf_dist[k] = dist[k - 1]**(-Y)
      
      for i in range(n):
          # calculate jumps
          jump[i] = tf_dist[i + 1] - tf_dist[i]
  
      return np.argmax(jump)
  
#+END_SRC

** Example distortion curves
[[file:img/distortion.png]]

** Our data clustering algorithm
1. Spline interpolation
2. Sampling (every minute)
3. Finding the number of clusters
4. K-means

* Algorithm output
** Data
[[file:img/data.png]]

** Interpolation: latitude
[[file:img/lat_interp.png]]

** Interpolation: longitude
[[file:img/lon_interp.png]]

** Distortion curve
[[file:img/dist.png]]

** Clustered data
[[file:img/data-clustered.png]]

** Clustered data
[[file:img/data-clustered2.png]]

** Clustered data
[[file:img/data-clustered3.png]]

** Clustered data
[[file:img/data-clustered4.png]]

** Clustered data
[[file:img/data-clustered5.png]]

* Future work
** Android implementation
1. GPS Logger has to be rewritten from scratch, this time fully implementing
   Location Strategies described in Android API Guides
2. Logger could be extended with the addition of accelerometer data collection,
   which could prove useful in discovering of e.g. the 'Traffic' or 'Movement' 
   domains, as well as in extending the interval between consecutive GPS data logs.
3. Data collection and processing model has to bo designed
4. A numerical library has to be picked, 2 solutions proposed:
   - Java libraries -- translation into Dalvik format (whol JARs or selected classes)
   - NDK with C libraries
5. Integration with a rule framework, e.g HeaRTDroid

** Algorithm improvement
*** Clustering while in travel                                     :B_normal:
    :PROPERTIES:
    :BEAMER_env: normal
    :END:
How to cluster the data collected while travelling?
+ Several clusters, or
+ One cluster ("the road")

* The end                                                   :B_ignoreheading:
  :PROPERTIES:
  :BEAMER_env: ignoreheading
  :END:
** References
#+BEGIN_LaTeX
  \begin{thebibliography}{10}    
  \bibitem{information-theoretic-approach}
    Catherine A. Sugar and Gareth M. James
    \newblock {\em Finding the number of clusters in a data set: An information theoretic approach}
    \newblock Marshall School of Business, University of Southern California
  \end{thebibliography}
  
#+END_LaTeX
** 
#+BEGIN_LaTeX
  \begin{center}
    \large{
      Thank you for your attention!
      \\ 
      \vfill
      Any questions? 
      \vfill
      ~~~~\url{http://geist.agh.edu.pl}
    }
    \vspace{1em}
    \\\includegraphics[scale=0.13]{img/geist-logo.png}~~~\includegraphics[scale=0.10]{img/agh-logo.png}
  \end{center}
  
#+END_LaTeX
